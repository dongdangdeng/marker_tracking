{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, window_name=\"img\"):\n",
    "    cv2.startWindowThread()\n",
    "    cv2.imshow(window_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鮮鋭化フィルタ\n",
    "def applyFiltersSp(img, k=2):\n",
    "    sharp_kernel = np.array([\n",
    "        [-k / 9, -k / 9, -k / 9],\n",
    "        [-k / 9, 1 + 8 * k / 9, k / 9],\n",
    "        [-k / 9, -k / 9, -k / 9]\n",
    "    ], np.float32)\n",
    "    img_sp = cv2.filter2D(img, -1, sharp_kernel).astype(\"uint8\")\n",
    "    return img_sp\n",
    "\n",
    "# バイラテラルフィルタ\n",
    "def applyFiltersBltrl(img, d=15):\n",
    "    img_bltrl = cv2.bilateralFilter(src=img, d=d, sigmaColor=75, sigmaSpace=75)\n",
    "    return img_bltrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 軌跡データ\n",
    "# csv_path = \"output/test/markers_t_hd_60.csv\"  # フィルタ適用前\n",
    "# csv_path = \"output/test/markers_t_h_60_comlement_filter_bltrl_hybrid_2.csv\" # フィルタ適用後+スプライン補完\n",
    "# csv_path = \"output/test/markers_t_h_60_liner_comlement_filter_bltrl_hybrid.csv\" # フィルタ適用後+線形補完\n",
    "csv_path = \"output/test/markers_base_4k_60_liner_filter.csv\"\n",
    "movie_path = \"src/mov/VibrationTest/base_4k_60.MOV\"\n",
    "markers_raw = pd.read_csv(csv_path, header=[0, 1])\n",
    "frames = len(markers_raw)\n",
    "\n",
    "# 解析で使用するidのデータだけ抜き出し\n",
    "ids = list(map(lambda col: str(col), [12, 13, 14]))\n",
    "markers_origin = markers_raw[ids]\n",
    "\n",
    "# 構造（線の接続関係）の定義\n",
    "stractures = [[12,13,14]]\n",
    "\n",
    "# 検出したい距離の定義\n",
    "distancees = [[13,14],[14,12]]\n",
    "\n",
    "# ストラクチャーに定義されているマーカーidのSeries\n",
    "stractures_ids = pd.Series(sum(stractures, [])).drop_duplicates().sort_values()\n",
    "\n",
    "\n",
    "# ids = pd.Series(markers.columns.levels[0])  # カラムのid列を取得\n",
    "# ids_mask = pd.Series(map(lambda id: str(id).isnumeric(), ids))  # 数値を真、文字列を偽とするマスクを作成\n",
    "# ids = ids.loc[ids_mask] # マスクを使って数値（id）のみを抜き出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 動画データ\n",
    "cap = cv2.VideoCapture(movie_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))    # 動画のfps\n",
    "ret, frame = cap.read()\n",
    "h_origin, w_origin = frame.shape[:2]\n",
    "\n",
    "# 動画サイズが大きすぎる場合はリサイズする\n",
    "h_max = 800\n",
    "if h_origin > h_max:\n",
    "    resize_ratio = h_max / h_origin # 縮小比率\n",
    "    h = int(h_origin * resize_ratio)\n",
    "    w = int(w_origin * resize_ratio)\n",
    "    markers = markers_origin * resize_ratio\n",
    "\n",
    "# 保存設定\n",
    "fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') \n",
    "writer = cv2.VideoWriter('./output/tracking_test.mp4', fmt, fps, (w, h))\n",
    "\n",
    "cpxy = ['cpx', 'cpy']\n",
    "pos = [None, None]\n",
    "pos_van = [None, None]\n",
    "pos_lnr = [None, None]\n",
    "pos_spr = [None, None]\n",
    "orbits_van = pd.DataFrame()  # 元データの軌跡\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "for id in ids:\n",
    "    # print(\"id :\", id)\n",
    "    for i, cp in enumerate(cpxy):\n",
    "        pos[i] = markers[str(id), cp]\n",
    "        pos_van[i] = pos[i]\n",
    "    orbits_van[id] = list(zip(\n",
    "        pos_van[0].astype(int), \n",
    "        pos_van[1].astype(int)\n",
    "        ))\n",
    "\n",
    "speed_x = pd.Series([], dtype=float)\n",
    "speed_y = pd.Series([], dtype=float)\n",
    "acceleration_x = pd.Series([], dtype=float)\n",
    "acceleration_y = pd.Series([], dtype=float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.37037\n",
       "1       0.37037\n",
       "2       0.37037\n",
       "3       0.37037\n",
       "4       0.37037\n",
       "         ...   \n",
       "3635    0.37037\n",
       "3636    0.37037\n",
       "3637    0.37037\n",
       "3638    0.37037\n",
       "3639    0.37037\n",
       "Name: (12, cpx), Length: 3640, dtype: float64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markers[('12', 'cpx')] / markers_origin[('12', 'cpx')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_x = pd.Series([], dtype=float)\n",
    "speed_y = pd.Series([], dtype=float)\n",
    "acceleration_x = pd.Series([], dtype=float)\n",
    "acceleration_y = pd.Series([], dtype=float)\n",
    "\n",
    "for f in range(frames):\n",
    "    ret, img = cap.read()\n",
    "    if not ret or cv2.waitKey(int(1000 / fps)) == 27:\n",
    "        break\n",
    "    img = cv2.resize(img, dsize=(w, h))\n",
    "\n",
    "    cv2.putText(img, f\"frame: {f}\", (10,20), font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    # img = np.zeros((h, w, 3))\n",
    "\n",
    "    # フィルター\n",
    "    img_f = applyFiltersBltrl(img)\n",
    "    img_f = applyFiltersSp(img_f)\n",
    "\n",
    "    # マーカー認識\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(img_f, dictionary)\n",
    "    # マーカー可視化\n",
    "    aruco.drawDetectedMarkers(img, corners, ids, (0, 255, 255))\n",
    "\n",
    "    # 定義した構造から線を描画（元データ利用）\n",
    "    positions = np.array(list(orbits_van.iloc[f]))\n",
    "    lines_from_stractures = []\n",
    "    for line in stractures:\n",
    "        for pos in line:\n",
    "            lines_from_stractures.append(list(orbits_van.iloc[f][str(pos)]))\n",
    "        # print(lines_from_stractures)\n",
    "        cv2.polylines(img, np.array([lines_from_stractures]), False, (0,0,255), 2)\n",
    "        # lines_from_stractures = []\n",
    "\n",
    "    # 座標間の距離を求めて描画\n",
    "    for ids in distancees:\n",
    "        pos1_x, pos1_y, pos1_z = [\n",
    "            markers.iloc[f][(str(ids[0]), 'x')], \n",
    "            markers.iloc[f][(str(ids[0]), 'y')], \n",
    "            markers.iloc[f][(str(ids[0]), 'z')]\n",
    "            ]\n",
    "        pos2_x, pos2_y, pos2_z = [\n",
    "            markers.iloc[f][(str(ids[1]), 'x')], \n",
    "            markers.iloc[f][(str(ids[1]), 'y')], \n",
    "            markers.iloc[f][(str(ids[1]), 'z')]\n",
    "            ]\n",
    "        distance = np.round(np.sqrt((pos1_x - pos2_x)**2 + (pos1_y - pos2_y)**2 + (pos1_z - pos2_z)**2), 2)\n",
    "        write_pos = (int((markers.iloc[f][(str(ids[0]), 'cpx')] + markers.iloc[f][(str(ids[1]), 'cpx')])/2),\n",
    "                     int((markers.iloc[f][(str(ids[0]), 'cpy')] + markers.iloc[f][(str(ids[1]), 'cpy')])/2))\n",
    "        cv2.putText(img, f\"[{ids[0]}]-[{ids[1]}]{distance}m\", write_pos, font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 座標から速度と加速度を求める\n",
    "    if f > 1:\n",
    "        for i, id in enumerate(stractures_ids):\n",
    "            speed_x_current = round(((markers[(str(id), 'x')][f] - markers[(str(id), 'x')][f - 1])) / (fps / 1000), 2)\n",
    "            if f < 3 : speed_x[i] = 0\n",
    "            acceleration_x[i] = round((speed_x_current - speed_x[i]) / (fps / 1000), 2)\n",
    "            speed_x[i] = speed_x_current\n",
    "            txt = f\"[{id}] spd x: {speed_x_current}m/sec | acc x: {acceleration_x[i]}m/sec^2\"\n",
    "            cv2.putText(img, txt, (10,40 + i * 20), font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "\n",
    "    # # 通常データを描画（<NA>が入っていれば描画しない）\n",
    "    # lines_pos_van = np.array(list(orbits_van.iloc[f]))\n",
    "    # count_nan = pd.Series(list(map(lambda t: pd.Series(t).isna().sum() ,lines_pos_van))).sum()\n",
    "    # # if count_nan == 0:\n",
    "    # #     cv2.polylines(img, [lines_pos_van], True, (0,255,255), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"mov\", img)\n",
    "    writer.write(img)\n",
    "    # print(f, lines_pos_spr)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39_opencv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bb47faea8ee0d84de6fa0e75bf000039a384b2a0a3d80fbde05930f393b2eba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
